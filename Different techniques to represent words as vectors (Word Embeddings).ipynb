{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I’m creating 4 sentences on which we’ll apply each of these techniques and understand how they work. For each of the techniques, I’ll use lowercase words only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Identify unique words in the complete text data  For each sentence, we’ll create an array of zeros with the same length as the length of the unique words vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['He is playing in the field',\n",
    "             'He is running towards the football.',\n",
    "             'The football game ended.',\n",
    "             'It started raining while everyone was playing in the field.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "sentence_vectors = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ended', 'everyone', 'field', 'football', 'game', 'he', 'in', 'is', 'it', 'playing', 'raining', 'running', 'started', 'the', 'towards', 'was', 'while']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_vectors.toarray()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Count Vectorizer converts each sentence into its own vector, it does not consider the importance of a word across the complete list of sentences. For example, He is in two sentences and it provides no useful information in differentiating between the two. Thus, it should have a lower weight in the overall vector of the sentence. This is where the TF-IDF Vectorizer comes into the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the word 'he'\n",
    "\n",
    "Total documents (N): 4\n",
    "\n",
    "Documents in which the word appears (n): 2\n",
    "\n",
    "Number of times the word appears in the first sentence: 1\n",
    "\n",
    "Number of words in the first sentence: 6\n",
    "\n",
    "Term Frequency(TF) = 1\n",
    "\n",
    "Inverse Document Frequency(IDF) = log(N/n)\n",
    "\n",
    "                                = log(4/2)\n",
    "                                \n",
    "                                = log(2)\n",
    "TF-IDF value = 1 * log(2)\n",
    "\n",
    "             = 0.69314718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn calculates tfidf in a different way :  1 * (log(N/n) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He is playing in the field',\n",
       " 'He is running towards the football.',\n",
       " 'The football game ended.',\n",
       " 'It started raining while everyone was playing in the field.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.69314718 0.         0.         1.69314718\n",
      "  1.69314718 1.69314718 0.         1.69314718 0.         0.\n",
      "  0.         1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.69314718 0.         1.69314718\n",
      "  0.         1.69314718 0.         0.         0.         2.38629436\n",
      "  0.         1.         2.38629436 0.         0.        ]\n",
      " [2.38629436 0.         0.         1.69314718 2.38629436 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.         0.         0.         0.        ]\n",
      " [0.         2.38629436 1.69314718 0.         0.         0.\n",
      "  1.69314718 0.         2.38629436 1.69314718 2.38629436 0.\n",
      "  2.38629436 1.         0.         2.38629436 2.38629436]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm = False, smooth_idf = False)\n",
    "sentence_vectors = vectorizer.fit_transform(sentences)\n",
    "print(sentence_vectors.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are a set of neural network models that have the aim to represent words in the vector space. These models are highly efficient and performant in understanding the context and relation between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two models in this class:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---CBOW (Continuous Bag of Words): The neural network takes a look at the surrounding words (say 2 to the left and 2 to the right) and predicts the word that comes in between\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---Skip-grams: The neural network takes in a word and then tries to predict the surrounding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIn = \"string.with.punctuation!\"\n",
    "punct = str.maketrans(\"\",\"\",string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_low = list(map(lambda x: x.lower(), sentences))\n",
    "sentences_tok = list(map(lambda x: x.split(), sentences_low))\n",
    "rem_punct = list(map(lambda x: [elem.translate(punct) for elem in x], sentences_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is', 'playing', 'in', 'the', 'field'],\n",
       " ['he', 'is', 'running', 'towards', 'the', 'football'],\n",
       " ['the', 'football', 'game', 'ended'],\n",
       " ['it',\n",
       "  'started',\n",
       "  'raining',\n",
       "  'while',\n",
       "  'everyone',\n",
       "  'was',\n",
       "  'playing',\n",
       "  'in',\n",
       "  'the',\n",
       "  'field']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common word to football is: ('raining', 0.9496791958808899)\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(rem_punct, workers = 1, size = 2, min_count = 1, window = 3, sg = 0)\n",
    "similar_word = model.wv.most_similar('football')\n",
    "print(\"Most common word to football is: {}\".format(similar_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0f60>,\n",
       " 'is': <gensim.models.keyedvectors.Vocab at 0x1e5f66e03c8>,\n",
       " 'playing': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0da0>,\n",
       " 'in': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0390>,\n",
       " 'the': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0dd8>,\n",
       " 'field': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0d68>,\n",
       " 'running': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0400>,\n",
       " 'towards': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0d30>,\n",
       " 'football': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0e48>,\n",
       " 'game': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0cf8>,\n",
       " 'ended': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0438>,\n",
       " 'it': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0c50>,\n",
       " 'started': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0cc0>,\n",
       " 'raining': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0c18>,\n",
       " 'while': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0c88>,\n",
       " 'everyone': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0be0>,\n",
       " 'was': <gensim.models.keyedvectors.Vocab at 0x1e5f66e0358>}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
